[**HOME**](Home) > [**SNOWPLOW SETUP GUIDE**](Setting-up-SnowPlow)

Setting up SnowPlow is a five step process:

1. [Setup a SnowPlow Collector](#step1)
2. [Setup a SnowPlow Tracker](#step2)
3. [Setup EmrEtlRunner](#step3)
4. [Setting up alternative data stores (e.g. Infobright, Redshift)](#step4)
5. [Analyse your data!](#step5)

<a name="step1" />
## Step 1: Setup a SnowPlow Collector

[[/images/2-collectors.png]] 

The SnowPlow collector receives data from SnowPlow trackers and logs that data to S3 for storage and further processing. Setting up a collector is the first step in the SnowPlow setup process.

[Setup a SnowPlow collector now!](Setting-up-a-collector)

Setup your collector? Then proceed to [step 2: setup a tracker](#step2).

<a name="step2" />
## Step 2: Setup a SnowPlow Tracker

[[/images/1-trackers.png]] 

SnowPlow trackers generate event data and send that data to SnowPlow collectors to be captured. The most common SnowPlow tracker used is the Javascript tracker, which is integrated in websites (either directly or via a tag management solution) the same way that any web analytics tracker (e.g. Google Analytics or Omniture tags) is integrated.

[Setup a tracker now!](Setting-up-a-Tracker)

**Note: once you have setup a collector and tracker, you can pause and perform the remainder of the setup steps later**. That is because your data is being successfully generated and logged. When you eventually proceed to [step 3: Setup EMrEtlRunner](#step3), you will be able to process all the data you have logged since setup.

Setup your tracker? Now proceed to [step 3: setup EmrEtlRunner](#step3).

<a name="step3" />
## Step 3: Setup EmrEtlRunner

[[/images/3-etl.png]] 

The EmrEtlRunner application regularly takes the raw log files generated by the SnowPlow collector and

1. **Cleans up the data** into a format that is easier to parse / analyse
2. **Enriches the data** (e.g. infers the location of the visitor from his / her IP address and infers the search engine keywords from the query string)
3. **Stores that cleaned, enriched data in S3**

Once you have setup EmrEtlRunner, the process for taking the raw data generated by the collector, cleaning and enriching it will be automated.

[Setup EmrEtlRunner now!](Setting-up-EmrEtlRunner)

Setup EmrEtlRunner? Proceed to [step 4: setup the StorageLoader](#step4).

<a name="step4" />
## Step 4: Setup the alternative data stores (e.g. Infobright, Redshift)

[[/images/4-storage.png]] 

Most SnowPlow users store their web event data in at least two places: S3 for processing in Hadoop (e.g. to enable machine learning via Mahout) and a columnar database (e.g. Infobright or Redshift) for more traditional OLAP analysis.

The StorageLoader is an application to regularly transfer data from S3 into other databases e.g. Infobright or Redshift. If you **only** wish to process your data using Hadoop on EMR, you do not need to setup the StorageLoader. However, if you would find it convenient to have your data in another data store (e.g. Infobright or Redshift) then you can set this up at this stage.

[Setup alternative data stores](Setting-up-alternative-data-stores).

Setup the alternative data stores? Then proceed to [step 5: analyse your data](#step5).

<a name="step5" />
## Step 5: Analyse your data!

[[/images/5-analytics.png]] 

Once your data is stored in S3 and Infobright, setup is complete and you are in a position to start analysing it. As part of the setup guide we run through the steps necessary to perform some intiial analysis and plugin a couple of analytics tools, to get you started.

[Get started analysing SnowPlow data](Getting-started-analysing-SnowPlow-data)

## Setup is complete!

![architecture] [conceptual-architecture]

You now have all five SnowPlow subsystems working!

[conceptual-architecture]: https://d3i6fms1cm1j0i.cloudfront.net/github-wiki/images/conceptual-architecture.png
