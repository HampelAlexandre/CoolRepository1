<a name="top" />

[**HOME**](Home) > [**SNOWPLOW SETUP GUIDE**](Setting-up-SnowPlow) > [**Step 3: setting up EmrEtlRunner **](Setting-up-a-EmrEtlRunner)

[[/images/e-etl.png]]

SnowPlow [EmrEtlRunner] [emr-etl-runner] is an application that parses the log files generated by your SnowPlow collector and

* Cleans the data (e.g. extracting name value pairs from query strings)
* Enriches the data (e.g. infers location from IP addresses)
* Writes the cleaned, enriched data to a new location in S3 where it can be queried directly using Hive / Pig / Mahout / Hadoop on EMR, or loaded into a database (e.g. Infobright, Redshift) for processing using traditional, SQL-based analytics tools.

This guide covers how to setup EmrEtlRunner including scheduling it so that your event data is automatically fetched from the collector logs, processed and updated in your cleaned data store on S3. It is divided into three sections:

1. [Installation] [installation]. You need to install EmrEtlRunner on your own server. It will interact with Amazon S3 via the Amazon API.
2. [Usage] [usage]. How to use EmrEtlRunner at the command line, to instuct it to process data from your collector. 
3. [Scheduling] [schedule]. How to schedule the tool so that you always have an up to date set of cleaned, enriched data available for analysis.

To start with [install] [installation] EmrEtlRunner.

[installation]: 1-Installing-EmrEtlRunner
[usage]: 2-Using-EmrEtlRunner
[scheduling]: 3-Scheduling-EmrEtlRunner
[emr-etl-runner]: https://github.com/snowplow/snowplow/tree/master/3-etl/emr-etl-runner