[**HOME**](Home) > [**SNOWPLOW TECHNICAL DOCUMENTATION**](Snowplow technical documentation) > [**Collectors**](collectors)

## Overview

Different Snowplow collectors write Snowplow data to logs of different formats.

Here we document the different formats, and show which collectors generate what. This document should be used by anyone:

1. Building a new collector, who would like to ensure it logs to a Snowplow supported format.
2. Building an ETL module, to ensure that the ETL module can successfully read the raw Snowplow logs generated by each collector, and write them to the [data structures](canonical-data-structure) used by the storage modules.

## Logging formats

1. Be it a record in a logfile or a raw event, it serves as an envelope containing the event data encapsulated within either the `GET` query string or the `POST` response object.
2. If it's inside the `POST` response object, then the events will be contained within [this JSON](https://github.com/snowplow/iglu-central/blob/master/schemas/com.snowplowanalytics.snowplow/payload_data/jsonschema/1-0-3).
3. With either `GET` or `POST`, the lowest level will be a set of name/value pairs that respect the [Snowplow Tracker Protocol](snowplow-tracker-protocol).

| **Logging formats**                   | **Description**                                 | **Status** | **Collector** |
|:--------------------------------------|:------------------------------------------------|:-----------|:--------------|
| [Cloudfront logs](#cloudfront)        | Amazon's Cloudfront log formats with Amazon Cloudfront filename naming convention | Supported (both pre and post Sept 2012 formats) | [[Cloudfront Collector]] |
| [Tomcat access logs](#tomcat)         | Tomcat access logs with Amazon Elastic Beanstalk filename naming convention | Supported | [[Clojure Collector]] |
| [Snowplow Thrift raw event](#thrift) | Binary serialized Thrift events | Supported | [[Scala Stream Collector]] |

<a name="cloudfront" />
## The Cloudfront logging format (with Cloudfront naming convention)

For the Cloudfront logfile naming convention, please, refer to the official [Amazon documentation](http://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/AccessLogs.html#AccessLogsFileNaming). The main point to note here is the logfiles are stored in `gzip` format, thus bearing `.gz` extension. They will be prefixed with the distribution ID:
 
`distribution-ID.YYYY-MM-DD-HH.unique-ID.gz`

The logging format is well described in [this section of the Amazon article](http://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/AccessLogs.html#BasicDistributionFileFormat). Each entry in a log file gives details about a single user request and the files bear the following characteristics.

* Use the [W3C extended log file format](http://www.w3.org/TR/WD-logfile.html).
* Contain tab-separated values.
* Contain records that are not necessarily in chronological order.
* Contain two header lines: one with the file-format version, and another that lists the W3C fields included in each record.
* Substitute URL-encoded equivalents for spaces and non-standard characters in field values.
* These non-standard characters consist of all ASCII codes below 32 and above 127. The URL encoding standard is [RFC 1738](http://www.ietf.org/rfc/rfc1738.txt).

Note that the actual field containing the key/value pairs from the `GET` requests initiated by the trackers is `cs-uri-query` (the 12th field).

Below is an example of a single record in the logfile.

`2016-01-20	20:22:55	IND6	480	174.2.224.27	GET	d2gtrjee5bqfpl.cloudfront.net	/i	200	https://www.properweb.ca/hosting/	Mozilla/5.0%2520(Windows%2520NT%25206.1)%2520AppleWebKit/537.36%2520(KHTML,%2520like%2520Gecko)%2520Chrome/47.0.2526.111%2520Safari/537.36	e=ue&ue_px=eyJzY2hlbWEiOiJpZ2x1OmNvbS5zbm93cGxvd2FuYWx5dGljcy5zbm93cGxvdy91bnN0cnVjdF9ldmVudC9qc29uc2NoZW1hLzEtMC0wIiwiZGF0YSI6eyJzY2hlbWEiOiJpZ2x1OmNvbS5zbm93cGxvd2FuYWx5dGljcy5zbm93cGxvdy9saW5rX2NsaWNrL2pzb25zY2hlbWEvMS0wLTEiLCJkYXRhIjp7InRhcmdldFVybCI6Imh0dHBzOi8vd3d3LnByb3BlcndlYi5jYS9ob3N0aW5nL2NvbXBhcmUtcGVyc29uYWwtcGxhbnMvIiwiZWxlbWVudElkIjoiIiwiZWxlbWVudFRhcmdldCI6IiJ9fX0&tv=js-2.5.3&tna=cf&aid=cfpweb&p=web&tz=America%252FGuatemala&lang=en-US&cs=UTF-8&f_pdf=1&f_qt=0&f_realp=0&f_wma=0&f_dir=0&f_fla=1&f_java=0&f_gears=0&f_ag=0&res=1152x864&cd=24&cookie=1&eid=a8451163-d056-4a6c-a8ef-c612aab3c252&dtm=1453321369503&vp=1152x329&ds=1135x2601&vid=3&sid=a2e39d3f-af4d-48f7-b153-8ca79942a552&duid=830e4863d85df04a&fp=1354193749&refr=https%253A%252F%252Fwww.properweb.ca%252Fdomain-name-registration%252F&url=https%253A%252F%252Fwww.properweb.ca%252Fhosting%252F	-	Hit	yavbRZy0qwso0j-8VBYB-VHIaJjo8K4eaARnXiseXDvKSH8vZ-_Mlg==	d2gtrjee5bqfpl.cloudfront.net	https	1268	0.001	-	TLSv1.2	ECDHE-RSA-AES128-GCM-SHA256	Hit`

The main points regarding Cloudfront logging are

1. Supports single events sent via `GET` **only**
2. No support for `network_userid`

Please, refer to the [Snowplow Tracker Protocol](snowplow-tracker-protocol) for the comprehensive list of the individual parameters that could be submitted with the `GET` request (and thus contained in the field `cs-uri-query` of the Cloudfront logfile).

<a name="tomcat" />
## The Tomcat access log format (with Amazon Elastic Beanstalk filename naming convention)

To ensure persistence of the logs, you have to configure your environment to publish logs to Amazon S3 automatically after they have been rotated. Elastic Beanstalk creates a bucket with the naming pattern `elasticbeanstalk-region-account-id` for each region in which you create environments. Within this bucket, logs are stored under the path `resources/environments/logs/logtype/environment-id/instance-id`.

For example, logs from instance `i-0a1fd158`, in Elastic Beanstalk environment `e-mpcwnwheky` in region `us-west-2` in account `0123456789012`, are stored in the following location:

`s3://elasticbeanstalk-us-west-2-0123456789012/resources/environments/logs/publish/e-mpcwnwheky/i-0a1fd158`

Please, refer to the following [Amazon article](http://docs.aws.amazon.com/elasticbeanstalk/latest/dg/using-features.logging.html) for more details.

Bear in mind that if you reconfigure the environment the `instance-id` could be modified too.

Access logging in Tomcat environment is performed by [valves that implement org.apache.catalina.AccessLog interface](https://tomcat.apache.org/tomcat-8.0-doc/config/valve.html#Access_Log_Valve). A formatting layout identifying the various information fields from the request and response to be logged is determined by the attribute `pattern`. The pattern we use ensures that the access log format matches that produced by the Cloudfront Collector (so that the same ETL process can be employed for both collectors).

`<Valve ... pattern="%{yyyy-MM-dd}t&#9;%{HH:mm:ss}t&#9;-&#9;%b&#9;%a&#9;%m&#9;%h&#9;%U&#9;%s&#9;%{Referer}i&#9;%{User-Agent}I&#9;%q&amp;cv=clj-1.1.0-%v&amp;nuid=%{sp}C&#9;-&#9;-&#9;-&#9;%~&#9;%w" />`

As a result, a logfile record will look like the one below

`174.2.224.27 - - [26/Jan/2016:02:18:33 +0000] "GET /i?e=pv&url=http%3A%2F%2Ffree.properweb.ca%2F&page=ProperWeb%20%7C%20Budget%20Web%20Solutions%20with%20Premium%20Features&tv=js-2.5.3&tna=cc&aid=cfpwfree&p=web&tz=America%2FGuatemala&lang=en-US&cs=UTF-8&f_pdf=1&f_qt=0&f_realp=0&f_wma=0&f_dir=0&f_fla=1&f_java=0&f_gears=0&f_ag=0&res=1152x864&cd=24&cookie=1&eid=54266cca-fa93-4c44-92b1-d0a5d4b77d27&dtm=1453774711474&vp=1152x763&ds=1152x763&vid=10&sid=d1571370-3922-4111-860a-042d9792dc54&duid=830e4863d85df04a&fp=1354193749 HTTP/1.1" 200 43 "http://free.properweb.ca/" "Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.111 Safari/537.36"`

The main characteristics of Tomacat access logs:

1. A custom textual format based on Apache logfile format
2. Support `GET` but also multiple events sent via `POST`
3. Support `network_userid`

<a name="thrift" />
## The Snowplow Thrift raw event format

TO WRITE
