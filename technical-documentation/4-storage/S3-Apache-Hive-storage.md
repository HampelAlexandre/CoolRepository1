[**HOME**](Home) > [**SNOWPLOW TECHNICAL DOCUMENTATION**](SnowPlow technical documentation) > [**Storage**](storage documentation)

## Contents

1. [Current table definition](#table-def)
2. [Future table definition incl. all planned fields](#future-table-def)
3. [Optimizing the table structure for query performance: roadmap](#roadmap)

<a name="table-def" />
## Current table definition

The standard S3 / Hive implementation of SnowPlow storage uses Apache Hive on EMR to store SnowPlow data in a table partitioned by date. The current table definition is as follows:

	CREATE EXTERNAL TABLE IF NOT EXISTS `events` (
	tm string,
	txn_id string,
	user_id string,
	user_ipaddress string,
	visit_id int,
	page_url string,
	page_title string,
	page_referrer string,
	mkt_source string,
	mkt_medium string,
	mkt_term string,
	mkt_content string,
	mkt_campaign string,
	ev_category string,
	ev_action string,
	ev_label string,
	ev_property string,
	ev_value string,
	tr_orderid string,
	tr_affiliation string,
	tr_total string,
	tr_tax string,
	tr_shipping string,
	tr_city string,
	tr_state string,
	tr_country string,
	ti_orderid string,
	ti_sku string,
	ti_name string,
	ti_category string,
	ti_price string,
	ti_quantity string,
	br_name string,
	br_family string,
	br_version string,
	br_type string,
	br_renderengine string,
	br_lang string,
	br_features array<string>,
	br_cookies boolean,
	os_name string,
	os_family string,
	os_manufacturer string,
	dvce_type string,
	dvce_ismobile boolean,
	dvce_screenwidth int,
	dvce_screenheight int,
	app_id string,
	platform string,
	event_name string,
	v_tracker string,
	v_collector string,
	v_etl string
	)
	PARTITIONED BY (dt STRING)
	LOCATION '${EVENTS_TABLE}' ;

<a name="future-table-def" />
## Future table definition (including all planned fields)

Note: whenever new fields are added to the Hive table, they are always added to the **end** of the table definition. As a result, there's no need to reprocess old data as new fields are added. (Because Hive simply sets the value of fields that are missing at the end of lines to `null`.) As a result, however, the ordering of the fields in the Hive table definition is not as tidy as it might be, reflecting when teh fields were added to the table definition, rather than a natural way of grouping columns together.

	CREATE EXTERNAL TABLE IF NOT EXISTS `events` (
	tm string,
	txn_id string,
	user_id string,
	user_ipaddress string,
	visit_id int,
	page_url string,
	page_title string,
	page_referrer string,
	mkt_source string,
	mkt_medium string,
	mkt_term string,
	mkt_content string,
	mkt_campaign string,
	ev_category string,
	ev_action string,
	ev_label string,
	ev_property string,
	ev_value string,
	tr_orderid string,
	tr_affiliation string,
	tr_total string,
	tr_tax string,
	tr_shipping string,
	tr_city string,
	tr_state string,
	tr_country string,
	ti_orderid string,
	ti_sku string,
	ti_name string,
	ti_category string,
	ti_price string,
	ti_quantity string,
	br_name string,
	br_family string,
	br_version string,
	br_type string,
	br_renderengine string,
	br_lang string,
	br_features array<string>,
	br_cookies boolean,
	os_name string,
	os_family string,
	os_manufacturer string,
	dvce_type string,
	dvce_ismobile boolean,
	dvce_screenwidth int,
	dvce_screenheight int,
	app_id string,
	mkt_referrerurl string,
	br_windowheight string,
	br_windowwidth string,
	br_colordepth string,
	br_jsversion string,
	os_version string,
	dvce_name string,
	dvce_isspider string,
	geo_country string,
	geo_region string,
	geo_city string,
	geo_postcode string,
	geo_latitude string,
	geo_longitude string,
	social_network string,
	social_action string,
	social_target string,
	social_pagepath string,
	click_targeturl string,
	click_targettype string,
	click_sourceid string,
	domain string,
	connection_type string,
	event_name string,
	cv_user1 string,
	cv_user2 string,
	cv_user3 string,
	cv_user4 string,
	cv_user5 string,
	cv_user6 string,
	cv_user7 string,
	cv_user8 string,
	cv_user9 string,
	cv_user10 string,
	cv_session1 string,
	cv_session2 string,
	cv_session3 string,
	cv_session4 string,
	cv_session5 string,
	cv_session6 string,
	cv_session7 string,
	cv_session8 string,
	cv_session9 string,
	cv_session10 string,
	cv_event1 string,
	cv_event2 string,
	cv_event3 string,
	cv_event4 string,
	cv_event5 string,
	cv_event6 string,
	cv_event7 string,
	cv_event8 string,
	cv_event9 string,
	cv_event10 string,
	cv_context1 string,
	cv_context2 string,
	cv_context3 string,
	cv_context4 string,
	cv_context5 string,
	cv_context6 string,
	cv_context7 string,
	cv_context8 string,
	cv_context9 string,
	cv_context10 string,
	cv_json string
	)
	PARTITIONED BY (dt STRING)
	LOCATION '${EVENTS_TABLE}' ;

<a name="roadmap" />
## Optimizing the table format for querying performance - roadmap

There are a variety of things that can be done to improve Hive querying performance on data in S3 and a number of these involve changing the way data is structured in Hive. We have not yet had the chance to test the impact of them to see if any are worthwhile. We welcome any feedback from community members into which are worth exploring / implementing:

1. Changing the storage format of the files to e.g. to binary formats and/or columnar formats (e.g. `RCFile`).  
2. Bucketing data by `user_id`.
3. Using [Qubole](http://www.qubole.com/) as an alternative to EMR.